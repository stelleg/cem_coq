\section{Machine Code}

As described in the introduction, here we describe the machine semantics, and
how the bisimulation with the stack machine from the previous section works.
We can then write down the full bisimulation relation by composing the
relations. We thus end up with our final bisimulation proof, namely that the
call-by-need semantics bisimulate the machine semantics. 

\subsection{Machine Semantics}

The machine semantics are what one would expect given the instructions and
machine state. We omit the full semantics, though they are available in the
source Coq files. We have addition and subtraction for the purposes of
comparing, and the ability to check if a number is zero. 

Some of the less obvious semantics: a closure is represented as two machine
words, or \texttt{nat}s in our case. The first is an instruction pointer. The
second is an environment pointer pointing into the heap. Our current closure is
defined by our instruction pointer and environment pointer registers. 

On the stack, we differentiate between update markers and argument closures by
using a zero in place of an instruction pointer, therefore disallowing a zero
instruction pointer, in agreement with modern conventions. We can then check for
zero on the top of the stack, and in the case of This allows for  

\subsection{Bisimulation with Small Step $\mathcal{CE}$ Semantics}

We create our bisimulation on the basic blocks created by the compiler. We
relate the machine and small step states in fairly simple ways. The deBruijn
terms of the small step semantics are all replaced with pointers into
instruction memory, and we require that the mapping preserved compilation
equivalence. 

For execution of instructions, we relate each rule in the small step semantics
to a basic block of code. Note that we've artificially increased the number of
instructions in this case and could trivivally show that a sound optimization
removing all of the unconditional \texttt{jmp} instructions to the next
instruction. 

In the same way substitution is often modeled as a single step, when
implementing the lookup in the machine semantics we must convert our
\texttt{clu} to a an inductive lookup executed by machine instructions. Of
course, this takes a number of instructions proportional to the size of the
deBruijn index. 

Our heap relation is fairly striaghtforward. Each cell of the $\mathcal{CE}$
semantics corresponds with three machine words: for the closure there will be an
instruction pointer and an environment pointer, and then one machine words for
the environment continuation. A cell is equivalent to one of these triplets iff
the instruction pointer points to a basic block that is equivalent to the term,
and the environment pointers are equivalent modulo heap location isomorphism.

Note that we do require that the \texttt{new} instruction returns a block of
machine words. This is in contrast to flat representations, where it needs to
return blocks of variables sizes. This is also a situation in which the
simplicity of the $\mathcal{CE}$ machine is very valuable: because of this
constant sized closures, we don't need to worry about cases in which the
value closure that we update a heap location with has more free variables, and
therefore requires more space, leading to the need for indirections as in the
STG machine \cite{STG}.


