\section{Introduction}
Compilers are an attractive target for verification in part because the
amortized return on investment is high. Every time a program compiled with a
verified compiler is run, the proof ensures that the semantics of the source
language are being preserved through execution. Therefore, any reasoning done
about the source language, formal or informal, is guaranteed to be preserved. 

Existing work has focused on verifying \emph{strict}
languages~\cite{chlipala2007certified, leroy2012compcert}, which pre-compute
function arguments to values. This paper presents the first machine-verified
compiler of a non-strict language. Non-strict languages evaluate bound
expressions on-demand. It is generally accepted that the relation between a
non-strict language and the hardware it runs on is harder to reason about than
with strict languages.  Indeed, the vast majority of languages have strict
semantics by default largely for this reason. Reasoning formally about the
correctness of a non-strict compiler is similarly difficult. We make the
challenge even greater by ensuring that the most important optimization for
non-strict languages, sharing evaluation results between instance of a variable,
or call-by-need semantics, is implemented correctly. This turns out to be
particularly challenging: one must reason about updating expressions with values
in a heap. 

In being forced to prove correctness of evaluation, not just results, we gain a
very useful property: we can reason about operational properties, like time and
memory usage, as a function of our source semantics. This enables us to reason
about optimizations at the source level and have that reasoning be preserved to
machine code. For example, this enables us to prove that an optimization that
rewrites lambda terms will be a \emph{true} optimization, in the sense that it
will only speed up the resulting program. As another example, we will show later
that if we have a type system that we'd like to use to prove operational
properties, e.g. a substructural type system, then we can have those properties
provably preserved at the machine code level. 

The ability to reason about operational properties of the machine code using the
source semantics is an important one. Arguably, what one expect from a compiler
is to implement some simple semantics, and be \emph{at least as fast} as that
semantics. A transformation that occasionally significantly slows down a program
should be avoided at all costs, and the tools that this paper provides are a
step in the direction of being able to provably avoid this undesirable
situation.

Our approach is enabled by a recently developed abstract machine, the Cactus
Environment Machine ($\mathcal{CE}$)~\cite{?}. $\mathcal{CE}$ uses a shared
environment to share results between instances of a variable. It can be compiled
to machine code very succinctly, reducing the load for formal reasoning about
the compiler greatly. It is likely we would not have succeeded in (or even
attempted) creating a verified compiler of call-by-need without this approach.

\subsection{Main Result}
Here we give a high level overview of the main results of the paper, along with
informal statements of the main theorems.

Our source language is lambda calculus: 
$$ t ::= x \; | \; \lambda x.t \; | \; t \; t $$

Application is left associative, as usual, and without loss of generality we
use natural numbers for variables. Our target language is a simple machine
assembly language:

\begin{align}
  \tag{Machine Word}     c &\in \mathbb{N} \\
  \tag{Registers} r &::= ip \; | \; ep \; | \; r1 \; | \; r2 \; | \; r3 \\
  \tag{Write Operands}  wo &::= r \; | \; (r+c)* \\
  \tag{Read Operands}  ro &::= wo \; | \; c \\
  \tag{Instructions} i &::= \texttt{mov} \; ro \; wo \; 
                       | \; \texttt{new} \; wo \;
                       | \; \texttt{push} \; ro \; 
                       | \; \texttt{pop} \; wo \\
  \tag{Basic Block} bb &::= i : bb \; | \;  \texttt{jmp} \; ro \; \\
  \tag{Program}   p &::= [bb]
\end{align}

Our machine words are natural numbers, which can be written into registers or
the heap, which is a partial function, or finite map, from pointers $p$ to
words. Pointers can index into the heap or into the program. Our instructions
are a subset of standard instructions on modern machines. Ours consist of
\texttt{mov} instructions, direct and indirect \texttt{jmp}s, \texttt{inc}rements
and \texttt{dec}rements, a \texttt{new} instruction that returns a fresh heap
location, and \texttt{push} and \texttt{pop}.  Given our compiler, which we will
describe in later sections, which compiles a lambda term into a program, we
prove the following main result:

\begin{theorem}[Compiler Correctness]
Call-by-need semantics bisimulate machine semantics, and compilation
preserves this bisimulation relation.
\end{theorem}

We'll formalize this theorem in Section~\ref{sec:bisim}, but the bisimulation
ensures that we're correctly sharing the results of evaluation down to machine
code. Because the semantics are deterministic, we get the following corollary:   

\begin{corollary}[Correct Results]
If a term $t$ compiles to $p$, then call-by-need evaluates a term $t$ to a value
$v$ \emph{iff} $p$ executes on the machine to a state $s$, where $v$ and $s$ are
related by the bisimulation relation.
\end{corollary}

This corollary says that we get the correct value when we execute the assembly
program on the instruction machine. This is similar, though slightly stronger,
to the result from~\cite{chlipala2007certified}, where Chlipala shows the first
half of the \emph{iff}. Note that our bisimulation is significantly stronger
than this type of result, which only considers the input and output: our
bisimulation provides an equivalence of the execution paths of the source and
machine code.

In addition to the above lemma, because call-by-need is an optimization of
call-by-name, we get the following corollary for a relation $R$ between.

\begin{corollary}[Call-by-Name Correct Result]
If $t$ compiles to $p$, then $t$ evaluates to a value $v$ under call-by-name
semantics \emph{iff} $p$ executes on the instruction machine to $s$, where $s$
and $v$ are related appropriately.
\end{corollary}

This is a valuable corollary because it means a programmer can reason about the
simpler $\beta$ reduction-based call-by-name semantics, and be confident that
their reasoning is preserved through compilation and execution.

\subsection{Contributions}
There are two primary contributions of this paper. 
\begin{itemize}
\item The first verified compiler of a higher order language that proves that
the machine semantics \emph{bisimulate} the source semantics
\item The first verified compiler of a non-strict language
\end{itemize}

The bisimulation contribution is crucial: with just a proof of correct
\emph{results}, one can't reason formally about things like memory and time
requirements at the source level. This is doubly important for non-strict
languages where reasoning about time and space informally is particularly
challenging.

\subsection{Outline}
The compiler and proofs use a number of different representations, including
standard lambda calculus, lambda calculus with deBruijn indices, and a locally
nameless representation. The paper proceeds by describing each transformation that
the compiler makes, along with the bisimulation relations between the semantics.

Specifically, in Section~\ref{sec:cbn} we cover call by need semantics, including a
correction to the Ariola et. al's presentation`\cite{ariola1995call}. In Section
2 we cover the $\mathcal{CE}$ big step semantics and it's lock-step relation to
call-by-need.  In Section 3 we describe the $\mathcal{CE}$ small step semantics
and how it relates to the big step semantics. We finish the chain in Section 4,
describing the instruction machine semantics and it's relation to the
$\mathcal{CE}$ small step semantics. While this compiler is untyped, we use
Section 5 to discuss how one could incorporate a type system into the compiler.
We then discuss threats to validity in Section 6 and conclude in Section 7. 

The compiler and all the proofs are available as Coq source code at
\texttt{https://github.com/stelleg/cem\_coq}.


